{
    "summary": "This code initializes a Markov model, sets n-word considerations, and populates the word dictionary for generating next word probabilities. It generates sentences using the Markov chain model based on previous words and creates specified number of sentences using create_sentences function.",
    "details": [
        {
            "comment": "The code imports necessary libraries and defines classes for a Markov model. It initializes the word dictionary with default values, sets the number of words to consider (n), and provides an add_raw method to generate word n-tuples and next word probability dictionary from input sentences.",
            "location": "\"/media/root/Prima/works/generated_docs/autoup_doc/src/poster/bilibiliupload/mText.py\":0-30",
            "content": "from __future__ import division\nfrom collections import defaultdict\nimport string\nimport re\nimport numpy as np\nclass CountProbPair:\n    def __init__(self):\n        self.count = 0\n        self.prob = 0.0\nclass Markov:\n    def __init__(self, n=2):\n        #self.word_dict = defaultdict(lambda: defaultdict((int, float)))\n        self.word_dict = defaultdict(lambda: defaultdict(CountProbPair))\n        self.word_dict[('',)][''].prob = 0.0\n        self.word_dict[('',)][''].count = 0\n        self.n = n\n    def add_raw(self, sentences):\n        \"\"\" Generate word n-tuple and next word probability dict \"\"\"\n        n = self.n\n        assert type(sentences) == list\n#        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s', text)\n        # '' is a special symbol for the start of a sentence like pymarkovchain uses\n        for sentence in sentences:\n            assert type(sentence) == list\n            words = sentence  # split each sentence into its constituent words\n            if len(words) == 0:\n                continue"
        },
        {
            "comment": "This code populates a word dictionary by counting occurrences of words and their combinations in the given text. It then normalizes the counts to represent probabilities for each word following another word or an empty string.",
            "location": "\"/media/root/Prima/works/generated_docs/autoup_doc/src/poster/bilibiliupload/mText.py\":32-54",
            "content": "            # first word follows a sentence end\n            self.word_dict[(\"\",)][words[0]].count += 1\n            for j in range(1, n+1):\n                for i in range(len(words) - 1):\n                    if i + j >= len(words):\n                        continue\n                    word = tuple(words[i:i + j])\n                    self.word_dict[word][words[i + j]].count += 1\n                # last word precedes a sentence end\n                self.word_dict[tuple(words[len(words) - j:len(words)])][\"\"].count += 1\n        # We've now got the db filled with parametrized word counts\n        # We still need to normalize this to represent probabilities\n        for word in self.word_dict:\n            wordsum = 0\n            for nextword in self.word_dict[word]:\n                wordsum += self.word_dict[word][nextword].count\n            if wordsum != 0:\n                for nextword in self.word_dict[word]:\n                    self.word_dict[word][nextword].prob = self.word_dict[word][nextword].count / wordsum\n    def add_to_dict(self, text):"
        },
        {
            "comment": "This function generates word n-tuples and next word probability dictionary. It iterates through sentences, removing quotes and splitting them into words. For each sentence segment, it updates the count for the words based on their positions in the sentence. The special symbol \"''\" is used to denote start of a sentence, similar to how pymarkovchain uses it.",
            "location": "\"/media/root/Prima/works/generated_docs/autoup_doc/src/poster/bilibiliupload/mText.py\":55-77",
            "content": "        \"\"\" Generate word n-tuple and next word probability dict \"\"\"\n        n = self.n\n        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s', text)\n        # '' is a special symbol for the start of a sentence like pymarkovchain uses\n        for sentence in sentences:\n            sentence = sentence.replace('\"','') # remove quotes\n            words = sentence.strip().split()  # split each sentence into its constituent words\n            if len(words) == 0:\n                continue\n            # first word follows a sentence end\n            self.word_dict[(\"\",)][words[0]].count += 1\n            for j in range(1, n+1):\n                for i in range(len(words) - 1):\n                    if i + j >= len(words):\n                        continue\n                    word = tuple(words[i:i + j])\n                    self.word_dict[word][words[i + j]].count += 1\n                # last word precedes a sentence end\n                self.word_dict[tuple(words[len(words) - j:len(words)])][\"\"].count += 1"
        },
        {
            "comment": "The code initializes a Markov chain model by calculating word probabilities based on the frequency of words occurring in a given text corpus. The 'create_sentence' method generates a random sentence using the Markov chain model, and the 'next_word' method returns the next word given a sequence of previous words from the corpus.",
            "location": "\"/media/root/Prima/works/generated_docs/autoup_doc/src/poster/bilibiliupload/mText.py\":79-101",
            "content": "        # We've now got the db filled with parametrized word counts\n        # We still need to normalize this to represent probabilities\n        for word in self.word_dict:\n            wordsum = 0\n            for nextword in self.word_dict[word]:\n                wordsum += self.word_dict[word][nextword].count\n            if wordsum != 0:\n                for nextword in self.word_dict[word]:\n                    self.word_dict[word][nextword].prob = self.word_dict[word][nextword].count / wordsum\n    def create_sentence(self, start=(\"\",)):\n        # next word\n        sentence = list(start)\n        nxt = self.next_word(start)\n        while nxt:\n            sentence.append(nxt)\n            nxt = self.next_word(sentence[-self.n:])\n        return ' '.join(sentence)\n    def next_word(self, previous_words):\n        \"\"\"The next word that is generated by the Markov Chain\n        depends on a tuple of the previous words from the Chain\"\"\"\n        # The previous words may never have appeared in order in the corpus used to"
        },
        {
            "comment": "This code generates a word based on the previous words and creates sentences using these words. It checks if the previous words are in the dictionary, removes the earliest word if not found, and selects a random word from the available frequencies. The create_sentences function generates a specified number of sentences, each sentence generated by calling create_sentence with the initial start words.",
            "location": "\"/media/root/Prima/works/generated_docs/autoup_doc/src/poster/bilibiliupload/mText.py\":102-121",
            "content": "        # generate the word_dict. Consequently, we want to try to find the previous \n        # words in orde, but if they are not there, then we remove the earliest word\n        # one by one and recheck. This means that next word depends on the current state\n        # but possible not on the entire state\n        previous_words = tuple(previous_words)\n        if previous_words != (\"\",): # the empty string 1-tuple (singleton tuple) is always there\n            while previous_words not in self.word_dict:\n                previous_words = tuple(previous_words[1:])\n                if not previous_words:\n                    return \"\"\n        frequencies = self.word_dict[previous_words]\n        inv = [(v.prob,k) for k, v in frequencies.items()]\n        p, w = zip(*inv)\n        return np.random.choice(w,1,p)[0]\n    def create_sentences(self, num, start=(\"\",)):\n        par = \"\"\n        for _ in range(num):\n            par = par + self.create_sentence(start)\n        return par"
        }
    ]
}